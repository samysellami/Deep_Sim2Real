calib_env-v0_sac:
  n_timesteps: !!float 3e5  
  policy: 'MlpPolicy'
  learning_rate: !!float 3e-4
  buffer_size: 1000000
  batch_size: 256
  ent_coef: 'auto'
  gamma: 0.99
  tau: 0.005
  train_freq: 1
  gradient_steps: 1
  learning_starts: 100
  use_sde: True
  policy_kwargs: "dict(log_std_init=-3, net_arch=[256, 256])"


# Number of finished trials:  100
# Best trial:
# Value:  0.1925074764502946
calib_env-v0:
    n_timesteps: !!float 3e5  
    gamma: 0.9999
    policy: 'MlpPolicy'
    lr: 0.007202464744943781
    batch_size: 128
    buffer_size: 10000
    learning_starts: 0
    train_freq: 300
    tau: 0.005
    log_std_init: -0.7260682336855917
    net_arch: medium
# Writing report to /home/sami/Documents/P.h.D/P.h.D_codes/Main_codes/Deep_Sim2Real/deep_calibration/saved_models/sac/report_calib_env-v0_100-trials-10000-tpe-median_1620079872.csv


calib_env-v0_source:
  n_timesteps: !!float 3e5
  policy: 'MlpPolicy'
  learning_rate: !!float 7.3e-4
  buffer_size: 300000
  batch_size: 256
  ent_coef: 'auto'
  gamma: 0.98
  tau: 0.02
  train_freq: 64
  gradient_steps: 64
  learning_starts: 10000
  use_sde: True
  policy_kwargs: "dict(log_std_init=-3, net_arch=[256, 256])"

